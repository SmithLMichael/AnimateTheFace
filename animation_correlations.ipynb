{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Animation Correlations\n",
    "\n",
    "To calculate the correlations between Michael's animation videos and the video only videos, we must do three steps: \n",
    "1. Clean the datasets to remove participants who didn't perform as desired.\n",
    "2. Average columnwise to get the average ratings of a specific animation/video in a vector form.\n",
    "3. Calculate the correlation between the video_only condition and {mouth_only, eyes_only, and full_face} animation conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:955: UserWarning: Illegal line #1\n",
      "\t\"backend=TkAgg\"\n",
      "\tin file \"/Users/MichaelSmith/.matplotlib/matplotlibrc\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from cleanavgcorr import ParticipantResults\n",
    "import scipy.stats as st\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSV Files\n",
    "\n",
    "We read in CSV's to four lists: face, eyes, mouth, and vid_only. Each list contains twelve tuples, corresponding to the twelve videos that we tested participants on. Each tuple is of format (video_id, class ParticipantResults). \n",
    "\n",
    "*For anim_directory*: give the path to the 'val_ratings_result' folder in the 'animation_results' folder.\n",
    "\n",
    "*For vid_only_dir*: give the path to the 'videoOnly results' \n",
    "\n",
    "*For worker_info*: give the path to the worker_info.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim_directory = os.fsencode('/Users/MichaelSmith/Desktop/new_animation_result/ratings')\n",
    "# vid_only_dir = os.fsencode('/Users/MichaelSmith/Desktop/VideoOnly')\n",
    "# worker_info = pd.read_csv('/Users/MichaelSmith/Desktop/new_animation_result/workers/worker_info_new.csv', sep=',')\n",
    "\n",
    "anim_directory = os.fsencode('/Users/MichaelSmith/Desktop/Recent Desktop SSNL/new_animation_result/ratings')\n",
    "vid_only_dir = os.fsencode('/Users/MichaelSmith/Desktop/Recent Desktop SSNL/VideoOnly')\n",
    "\n",
    "#vid_only_dir = os.fsencode('/Users/MichaelSmith/Desktop/Full_vids') # this is the actual both conditions\n",
    "\n",
    "worker_info = pd.read_csv('/Users/MichaelSmith/Desktop/Recent Desktop SSNL/new_animation_result/workers/worker_info_new.csv', sep=',')\n",
    "\n",
    "face = {}\n",
    "mouth = {}\n",
    "eyes = {}\n",
    "vid_only = {}\n",
    "\n",
    "# FACE, EYES, MOUTH ANIMATION CONDITIONS\n",
    "for file in os.listdir(anim_directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        vid_id = filename[:10]\n",
    "        df = pd.read_csv(os.path.join(os.fsdecode(anim_directory), filename))\n",
    "        if 'face' in filename:\n",
    "            pr = ParticipantResults(vid_id + '_anim_face', df, worker_info)\n",
    "            face[vid_id] = pr\n",
    "        elif 'eyes' in filename:\n",
    "            pr = ParticipantResults(vid_id + '_anim_eyes', df, worker_info)\n",
    "            eyes[vid_id] = pr\n",
    "        else:\n",
    "            pr = ParticipantResults(vid_id + '_anim_mouth', df, worker_info)\n",
    "            mouth[vid_id] = pr\n",
    "\n",
    "# VIDEO ONLY CONDITION\n",
    "for file in os.listdir(vid_only_dir):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        vid_id = filename[:10]\n",
    "        df = pd.read_csv(os.path.join(os.fsdecode(vid_only_dir), filename))\n",
    "        pr = ParticipantResults(vid_id, df, worker_info)\n",
    "        vid_only[vid_id] = pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cleanavgcorr.ParticipantResults at 0x1a1b8f4780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face['ID118_vid3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {}\n",
    "\n",
    "target_dir = os.fsencode('/Users/MichaelSmith/Desktop/target')\n",
    "\n",
    "for file in os.listdir(target_dir):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        vid_id = filename[:10]\n",
    "        if vid_id in vid_only:\n",
    "            df = pd.read_csv(os.path.join(os.fsdecode(target_dir), filename))\n",
    "            targets[vid_id] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID128_vid2\n",
      "ID129_vid2\n",
      "ID161_vid3\n",
      "ID129_vid5\n",
      "ID135_vid3\n",
      "ID170_vid2\n",
      "ID171_vid1\n",
      "ID167_vid2\n",
      "ID153_vid3\n",
      "ID169_vid4\n",
      "ID120_vid4\n",
      "ID121_vid5\n",
      "ID174_vid2\n",
      "ID174_vid3\n",
      "ID120_vid1\n",
      "ID137_vid6\n",
      "ID118_vid3\n",
      "ID147_vid5\n",
      "ID151_vid2\n",
      "ID173_vid6\n",
      "ID181_vid2\n",
      "ID147_vid2\n",
      "ID119_vid4\n",
      "ID181_vid4\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Averaging\n",
    "First, we need to clean the CSV files before we can average the participants' ratings. The type of cleaning depends on\n",
    "the CSV. \n",
    "\n",
    "##### Removal Conditions:\n",
    "For the animation CSVs (only), we have information on the attention of the participants (time spent on the tab = i.e. 1 - time on other tab(s)); if attention falls below 75% **(subject to change)**, we remove that participant's trial results. For both the video-only and animation conditions, we remove a participant's trial if they do not move the slider bar at least three times **(subject to change)**. These variables can be changed in the ParticipantResults class.\n",
    "\n",
    "This leaves us with datasets of size (num_participants x time).\n",
    "##### Averaging:\n",
    "We average each dataset columnwise, across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num people thrown out for video ID173_vid6_anim_face: 4 out of 37 participants\n",
      "Num people thrown out for video ID173_vid6_anim_eyes: 2 out of 26 participants\n",
      "Num people thrown out for video ID173_vid6_anim_mouth: 3 out of 27 participants\n",
      "Num people thrown out for video ID173_vid6: 9 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID120_vid1_anim_face: 6 out of 35 participants\n",
      "Num people thrown out for video ID120_vid1_anim_eyes: 2 out of 23 participants\n",
      "Num people thrown out for video ID120_vid1_anim_mouth: 6 out of 32 participants\n",
      "Num people thrown out for video ID120_vid1: 5 out of 64 participants\n",
      "\n",
      "Num people thrown out for video ID174_vid2_anim_face: 5 out of 34 participants\n",
      "Num people thrown out for video ID174_vid2_anim_eyes: 4 out of 24 participants\n",
      "Num people thrown out for video ID174_vid2_anim_mouth: 4 out of 32 participants\n",
      "Num people thrown out for video ID174_vid2: 10 out of 69 participants\n",
      "\n",
      "Num people thrown out for video ID151_vid2_anim_face: 9 out of 30 participants\n",
      "Num people thrown out for video ID151_vid2_anim_eyes: 8 out of 25 participants\n",
      "Num people thrown out for video ID151_vid2_anim_mouth: 8 out of 35 participants\n",
      "Num people thrown out for video ID151_vid2: 11 out of 58 participants\n",
      "\n",
      "Num people thrown out for video ID135_vid3_anim_face: 1 out of 28 participants\n",
      "Num people thrown out for video ID135_vid3_anim_eyes: 4 out of 32 participants\n",
      "Num people thrown out for video ID135_vid3_anim_mouth: 4 out of 30 participants\n",
      "Num people thrown out for video ID135_vid3: 6 out of 56 participants\n",
      "\n",
      "Num people thrown out for video ID161_vid3_anim_face: 4 out of 28 participants\n",
      "Num people thrown out for video ID161_vid3_anim_eyes: 6 out of 30 participants\n",
      "Num people thrown out for video ID161_vid3_anim_mouth: 8 out of 32 participants\n",
      "Num people thrown out for video ID161_vid3: 13 out of 54 participants\n",
      "\n",
      "Num people thrown out for video ID169_vid4_anim_face: 7 out of 29 participants\n",
      "Num people thrown out for video ID169_vid4_anim_eyes: 7 out of 25 participants\n",
      "Num people thrown out for video ID169_vid4_anim_mouth: 12 out of 36 participants\n",
      "Num people thrown out for video ID169_vid4: 7 out of 50 participants\n",
      "\n",
      "Num people thrown out for video ID181_vid2_anim_face: 2 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2_anim_eyes: 4 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2_anim_mouth: 2 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2: 6 out of 67 participants\n",
      "\n",
      "Num people thrown out for video ID147_vid5_anim_face: 4 out of 31 participants\n",
      "Num people thrown out for video ID147_vid5_anim_eyes: 2 out of 29 participants\n",
      "Num people thrown out for video ID147_vid5_anim_mouth: 4 out of 30 participants\n",
      "Num people thrown out for video ID147_vid5: 6 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID167_vid2_anim_face: 4 out of 30 participants\n",
      "Num people thrown out for video ID167_vid2_anim_eyes: 7 out of 34 participants\n",
      "Num people thrown out for video ID167_vid2_anim_mouth: 8 out of 26 participants\n",
      "Num people thrown out for video ID167_vid2: 6 out of 63 participants\n",
      "\n",
      "Num people thrown out for video ID119_vid4_anim_face: 9 out of 27 participants\n",
      "Num people thrown out for video ID119_vid4_anim_eyes: 9 out of 32 participants\n",
      "Num people thrown out for video ID119_vid4_anim_mouth: 9 out of 31 participants\n",
      "Num people thrown out for video ID119_vid4: 8 out of 50 participants\n",
      "\n",
      "Num people thrown out for video ID120_vid4_anim_face: 0 out of 28 participants\n",
      "Num people thrown out for video ID120_vid4_anim_eyes: 5 out of 41 participants\n",
      "Num people thrown out for video ID120_vid4_anim_mouth: 3 out of 21 participants\n",
      "Num people thrown out for video ID120_vid4: 6 out of 55 participants\n",
      "\n",
      "Num people thrown out for video ID181_vid4_anim_face: 7 out of 34 participants\n",
      "Num people thrown out for video ID181_vid4_anim_eyes: 11 out of 33 participants\n",
      "Num people thrown out for video ID181_vid4_anim_mouth: 10 out of 23 participants\n",
      "Num people thrown out for video ID181_vid4: 6 out of 55 participants\n",
      "\n",
      "Num people thrown out for video ID129_vid5_anim_face: 3 out of 24 participants\n",
      "Num people thrown out for video ID129_vid5_anim_eyes: 4 out of 32 participants\n",
      "Num people thrown out for video ID129_vid5_anim_mouth: 2 out of 34 participants\n",
      "Num people thrown out for video ID129_vid5: 9 out of 65 participants\n",
      "\n",
      "Num people thrown out for video ID137_vid6_anim_face: 4 out of 23 participants\n",
      "Num people thrown out for video ID137_vid6_anim_eyes: 5 out of 28 participants\n",
      "Num people thrown out for video ID137_vid6_anim_mouth: 8 out of 39 participants\n",
      "Num people thrown out for video ID137_vid6: 9 out of 60 participants\n",
      "\n",
      "Num people thrown out for video ID118_vid3_anim_face: 5 out of 29 participants\n",
      "Num people thrown out for video ID118_vid3_anim_eyes: 6 out of 31 participants\n",
      "Num people thrown out for video ID118_vid3_anim_mouth: 8 out of 30 participants\n",
      "Num people thrown out for video ID118_vid3: 9 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID128_vid2_anim_face: 9 out of 33 participants\n",
      "Num people thrown out for video ID128_vid2_anim_eyes: 5 out of 29 participants\n",
      "Num people thrown out for video ID128_vid2_anim_mouth: 4 out of 28 participants\n",
      "Num people thrown out for video ID128_vid2: 15 out of 69 participants\n",
      "\n",
      "Num people thrown out for video ID147_vid2_anim_face: 3 out of 27 participants\n",
      "Num people thrown out for video ID147_vid2_anim_eyes: 7 out of 28 participants\n",
      "Num people thrown out for video ID147_vid2_anim_mouth: 3 out of 35 participants\n",
      "Num people thrown out for video ID147_vid2: 8 out of 51 participants\n",
      "\n",
      "Num people thrown out for video ID171_vid1_anim_face: 8 out of 39 participants\n",
      "Num people thrown out for video ID171_vid1_anim_eyes: 1 out of 30 participants\n",
      "Num people thrown out for video ID171_vid1_anim_mouth: 5 out of 21 participants\n",
      "Num people thrown out for video ID171_vid1: 13 out of 54 participants\n",
      "\n",
      "Num people thrown out for video ID170_vid2_anim_face: 3 out of 29 participants\n",
      "Num people thrown out for video ID170_vid2_anim_eyes: 5 out of 31 participants\n",
      "Num people thrown out for video ID170_vid2_anim_mouth: 5 out of 30 participants\n",
      "Num people thrown out for video ID170_vid2: 14 out of 56 participants\n",
      "\n",
      "Num people thrown out for video ID153_vid3_anim_face: 8 out of 32 participants\n",
      "Num people thrown out for video ID153_vid3_anim_eyes: 6 out of 39 participants\n",
      "Num people thrown out for video ID153_vid3_anim_mouth: 4 out of 19 participants\n",
      "Num people thrown out for video ID153_vid3: 8 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID129_vid2_anim_face: 8 out of 30 participants\n",
      "Num people thrown out for video ID129_vid2_anim_eyes: 5 out of 31 participants\n",
      "Num people thrown out for video ID129_vid2_anim_mouth: 4 out of 29 participants\n",
      "Num people thrown out for video ID129_vid2: 13 out of 61 participants\n",
      "\n",
      "Num people thrown out for video ID174_vid3_anim_face: 2 out of 25 participants\n",
      "Num people thrown out for video ID174_vid3_anim_eyes: 6 out of 32 participants\n",
      "Num people thrown out for video ID174_vid3_anim_mouth: 1 out of 33 participants\n",
      "Num people thrown out for video ID174_vid3: 9 out of 60 participants\n",
      "\n",
      "Num people thrown out for video ID121_vid5_anim_face: 7 out of 28 participants\n",
      "Num people thrown out for video ID121_vid5_anim_eyes: 2 out of 25 participants\n",
      "Num people thrown out for video ID121_vid5_anim_mouth: 6 out of 37 participants\n",
      "Num people thrown out for video ID121_vid5: 16 out of 66 participants\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can call clean as many times as possible - but cleaning only works once. Same with averaging.\n",
    "for key in vid_only:\n",
    "    face[key].clean()\n",
    "    face[key].compute_average()\n",
    "    eyes[key].clean()\n",
    "    eyes[key].compute_average()\n",
    "    mouth[key].clean()\n",
    "    mouth[key].compute_average()\n",
    "    vid_only[key].clean(anim=False)\n",
    "    vid_only[key].compute_average()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "print(len(eyes['ID118_vid3'].modded_df.index) / len(eyes['ID118_vid3'].orig_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431278472799235\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "for key in vid_only:\n",
    "    sum += len(vid_only[key].modded_df.index) / len(vid_only[key].orig_df.index)\n",
    "print(sum/len(vid_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21264300459055827\n"
     ]
    }
   ],
   "source": [
    "# in this cell -- we calculate the in-group correlations\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "corr_dict = {}\n",
    "\n",
    "#for key1 in vid_only:\n",
    "#    print(vid_only[key1].orig_df.shape)\n",
    "\n",
    "ex_arry = vid_only[key].modded_df.values\n",
    "ex_arry = ex_arry[:, 1:]\n",
    "\n",
    "divisor = ex_arry.shape[0] # 50\n",
    "\n",
    "big = 0\n",
    "\n",
    "for row_ind in range(ex_arry.shape[0]):\n",
    "    leave_out = ex_arry[row_ind, :]\n",
    "    rest = np.vstack((ex_arry[:row_ind, :], ex_arry[row_ind+1:, :]))\n",
    "    \n",
    "    indiv_corr = 0\n",
    "    for row2_ind in range(rest.shape[0]):\n",
    "        indiv_corr += np.arctanh(pearsonr(leave_out, rest[row2_ind])[0])\n",
    "        \n",
    "    big += indiv_corr/(divisor-1)\n",
    "\n",
    "        \n",
    "        \n",
    "print(np.tanh(big/divisor)) # probabilistic space transform...\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets['ID128_vid2'].drop('time', axis=1, inplace=True)\n",
    "\n",
    "for target in targets:\n",
    "    if 'time' in targets[target].columns:\n",
    "       targets[target].drop('time', axis=1, inplace=True)\n",
    "    targets[target] = targets[target].values.reshape((targets[target].shape[0],))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_only_modded = {}\n",
    "targs_modded = {}\n",
    "face_modded = {}\n",
    "mouth_modded = {}\n",
    "eyes_modded = {}\n",
    "\n",
    "\n",
    "for target in targets:\n",
    "    min_len = min(targets[target].shape[0], vid_only[target].average_df.shape[0], \n",
    "                  face[target].average_df.shape[0], mouth[target].average_df.shape[0],\n",
    "                 eyes[target].average_df.shape[0])\n",
    "    targs_modded[target] = pd.DataFrame(targets[target][:min_len])\n",
    "    vid_only_modded[target] = vid_only[target].average_df[:min_len]\n",
    "    face_modded[target] = face[target].average_df[:min_len]\n",
    "    mouth_modded[target] = mouth[target].average_df[:min_len]\n",
    "    eyes_modded[target] = eyes[target].average_df[:min_len]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some correlation with targets instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For video ID128_vid2: corr's btwn video_only and face, mouth, and eyes are: -0.652790, 0.375794, 0.160735\n",
      "For video ID129_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.097002, -0.359360, 0.202503\n",
      "For video ID161_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.757693, 0.657542, 0.017129\n",
      "For video ID129_vid5: corr's btwn video_only and face, mouth, and eyes are: -0.540616, -0.145447, -0.929643\n",
      "For video ID135_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.231837, -0.209989, -0.768572\n",
      "For video ID170_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.227392, 0.286742, -0.580640\n",
      "For video ID171_vid1: corr's btwn video_only and face, mouth, and eyes are: -0.219867, -0.018824, -0.503290\n",
      "For video ID167_vid2: corr's btwn video_only and face, mouth, and eyes are: -0.434347, -0.037496, 0.197091\n",
      "For video ID153_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.426130, 0.564521, 0.852168\n",
      "For video ID169_vid4: corr's btwn video_only and face, mouth, and eyes are: -0.722734, 0.122598, -0.880875\n",
      "For video ID120_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.577250, 0.136852, 0.170346\n",
      "For video ID121_vid5: corr's btwn video_only and face, mouth, and eyes are: -0.227584, -0.039818, -0.185800\n",
      "For video ID174_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.698984, 0.776378, 0.120888\n",
      "For video ID174_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.722007, 0.465585, 0.056700\n",
      "For video ID120_vid1: corr's btwn video_only and face, mouth, and eyes are: 0.160227, 0.365934, 0.091771\n",
      "For video ID137_vid6: corr's btwn video_only and face, mouth, and eyes are: -0.022268, -0.100438, 0.473352\n",
      "For video ID118_vid3: corr's btwn video_only and face, mouth, and eyes are: -0.098121, 0.034221, 0.645075\n",
      "For video ID147_vid5: corr's btwn video_only and face, mouth, and eyes are: 0.134948, -0.121667, 0.374037\n",
      "For video ID151_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.574586, 0.687360, 0.589406\n",
      "For video ID173_vid6: corr's btwn video_only and face, mouth, and eyes are: 0.374722, -0.666508, 0.207888\n",
      "For video ID181_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.478353, 0.696170, 0.537663\n",
      "For video ID147_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.076306, -0.013072, -0.189863\n",
      "For video ID119_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.814642, 0.642567, 0.759070\n",
      "For video ID181_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.271461, 0.569562, 0.594524\n",
      "Average Face Correlation:  0.18407412067730264\n",
      "Average Mouth Correlation:  0.22828932479792066\n",
      "Average Eyes Correlation:  0.06169736719110142\n"
     ]
    }
   ],
   "source": [
    "total_face = []\n",
    "face_pear_corr_vals = []\n",
    "\n",
    "total_mouth = []\n",
    "mouth_pear_corr_vals = []\n",
    "\n",
    "total_eyes = []\n",
    "eyes_pear_corr_vals = []\n",
    "\n",
    "dict_we_wanna_use = targs_modded\n",
    "div = len(dict_we_wanna_use)\n",
    "\n",
    "for key in dict_we_wanna_use:\n",
    "    sha = targs_modded[key].shape[0]\n",
    "    f = face_modded[key].values\n",
    "    m = mouth_modded[key].values\n",
    "    e = eyes_modded[key].values\n",
    "    t = targs_modded[key].values.reshape((sha,))\n",
    "    \n",
    "    face_corr = pearsonr(f, t)[0]\n",
    "    total_face.append(np.arctanh(face_corr))\n",
    "    face_pear_corr_vals.append(face_corr)\n",
    "    \n",
    "    mouth_corr = pearsonr(m, t)[0]\n",
    "    total_mouth.append(np.arctanh(mouth_corr))\n",
    "    mouth_pear_corr_vals.append(mouth_corr)\n",
    "    \n",
    "    eyes_corr = pearsonr(e, t)[0]\n",
    "    total_eyes.append(np.arctanh(eyes_corr))\n",
    "    eyes_pear_corr_vals.append(eyes_corr)\n",
    "    print('For video %s: corr\\'s btwn video_only and face, mouth, and eyes are: %5f, %5f, %5f' % (key, face_corr, mouth_corr, eyes_corr))\n",
    "    \n",
    "print('Average Face Correlation: ', np.tanh(np.sum(total_face)/div))\n",
    "print('Average Mouth Correlation: ', np.tanh(np.sum(total_mouth)/div))\n",
    "print('Average Eyes Correlation: ', np.tanh(np.sum(total_eyes)/div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c542198>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c5a1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'Face':face_pear_corr_vals, 'Mouth':mouth_pear_corr_vals, 'Eyes':eyes_pear_corr_vals}).boxplot(column=['Eyes', 'Face', 'Mouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in vid_only:\n",
    "    curr_arr = vid_only[key].modded_df.values[:, 1:] # to get rid of participant id's\n",
    "    divisor = curr_arr.shape[0]\n",
    "    \n",
    "    overall_corr = 0\n",
    "    \n",
    "    for row_ind in range(divisor):\n",
    "        leave_out = curr_arr[row_ind, :]\n",
    "        rest = np.vstack((curr_arr[:row_ind, :], curr_arr[row_ind+1:, :]))\n",
    "        \n",
    "        indiv_corr = 0\n",
    "        for row2_ind in range(rest.shape[0]):\n",
    "            indiv_corr += np.arctanh(pearsonr(leave_out, rest[row2_ind])[0])\n",
    "            \n",
    "        overall_corr += indiv_corr/(divisor-1)\n",
    "        \n",
    "    corr_dict[key] = np.tanh(overall_corr/divisor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09663977578392621, 0.19360972526154518, 0.21264300459055827, 0.22249030853734872, 0.2451487477151972, 0.24755847812442755, 0.24771655072178564, 0.28574609684478347, 0.28637124982607104, 0.29042670946295535, 0.3044029483380661, 0.32514147693337236, 0.33318216068570816, 0.35349735327689585, 0.371302249262075, 0.3841453530853013, 0.3892237850333407, 0.39829868442808375, 0.4010052360531072, 0.40381911335349197, 0.4414683122409104, 0.4617216651926436, 0.4856065119106889, 0.5898832057912969]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "top12 = {}\n",
    "bottom12 = {}\n",
    "mid12 = {}\n",
    "\n",
    "top6 = {}\n",
    "bottom6 = {}\n",
    "\n",
    "allofthem = []\n",
    "\n",
    "for key in corr_dict:\n",
    "    \n",
    "    allofthem.append(corr_dict[key])\n",
    "    \n",
    "    if corr_dict[key] > .40:\n",
    "        top6[key] = corr_dict[key]\n",
    "        \n",
    "    if corr_dict[key] <= .40 and corr_dict[key] >= .2476:\n",
    "        mid12[key] = corr_dict[key]\n",
    "        \n",
    "    if corr_dict[key] < .2476:\n",
    "        bottom6[key] = corr_dict[key]\n",
    "    \n",
    "    if corr_dict[key] > .33:\n",
    "        #print(corr_dict[key])\n",
    "        top12[key] = corr_dict[key]\n",
    "    else:\n",
    "        bottom12[key] = corr_dict[key]\n",
    "        \n",
    "print(sorted(allofthem))\n",
    "print(len(mid12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlating\n",
    "\n",
    "For each of the three conditions ({eyes_only, jaw/mouth_only, full_face}), we correlate with the video_only condition for each video before averaging across all videos. We use pearson's r for correlating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For video ID173_vid6: corr's btwn video_only and face, mouth, and eyes are: 0.758982, -0.125961, 0.005120\n",
      "For video ID120_vid1: corr's btwn video_only and face, mouth, and eyes are: 0.820400, 0.231546, -0.164377\n",
      "For video ID174_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.548788, 0.342210, -0.505821\n",
      "For video ID135_vid3: corr's btwn video_only and face, mouth, and eyes are: -0.264098, 0.554585, 0.690425\n",
      "For video ID147_vid5: corr's btwn video_only and face, mouth, and eyes are: -0.193039, 0.391303, -0.073037\n",
      "For video ID181_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.860411, 0.907085, -0.127113\n",
      "For video ID137_vid6: corr's btwn video_only and face, mouth, and eyes are: 0.188076, 0.164637, -0.440402\n",
      "For video ID118_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.076164, -0.195537, -0.337808\n",
      "For video ID147_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.049605, 0.588132, -0.227755\n",
      "For video ID170_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.746535, 0.848766, -0.194188\n",
      "For video ID153_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.594459, 0.584336, 0.926725\n",
      "For video ID129_vid2: corr's btwn video_only and face, mouth, and eyes are: -0.762712, -0.243365, 0.095808\n",
      "Average Face Correlation:  0.3627558258061037\n",
      "Average Mouth Correlation:  0.4171048173352061\n",
      "Average Eyes Correlation:  0.03397551129417662\n"
     ]
    }
   ],
   "source": [
    "total_face = []\n",
    "face_pear_corr_vals = []\n",
    "\n",
    "total_mouth = []\n",
    "mouth_pear_corr_vals = []\n",
    "\n",
    "total_eyes = []\n",
    "eyes_pear_corr_vals = []\n",
    "\n",
    "dict_we_wanna_use = mid12\n",
    "\n",
    "div = len(dict_we_wanna_use)\n",
    "\n",
    "for key in dict_we_wanna_use:\n",
    "    face_corr = face[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_face.append(np.arctanh(face_corr))\n",
    "    face_pear_corr_vals.append(face_corr)\n",
    "    \n",
    "    mouth_corr = mouth[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_mouth.append(np.arctanh(mouth_corr))\n",
    "    mouth_pear_corr_vals.append(mouth_corr)\n",
    "    \n",
    "    eyes_corr = eyes[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_eyes.append(np.arctanh(eyes_corr))\n",
    "    eyes_pear_corr_vals.append(eyes_corr)\n",
    "    print('For video %s: corr\\'s btwn video_only and face, mouth, and eyes are: %5f, %5f, %5f' % (key, face_corr, mouth_corr, eyes_corr))\n",
    "    \n",
    "print('Average Face Correlation: ', np.tanh(np.sum(total_face)/div))\n",
    "print('Average Mouth Correlation: ', np.tanh(np.sum(total_mouth)/div))\n",
    "print('Average Eyes Correlation: ', np.tanh(np.sum(total_eyes)/div))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a10bfc6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a10bfcb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'Face':face_pear_corr_vals, 'Mouth':mouth_pear_corr_vals, 'Eyes':eyes_pear_corr_vals}).boxplot(column=['Eyes', 'Face', 'Mouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
