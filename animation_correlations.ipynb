{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Animation Correlations\n",
    "\n",
    "To calculate the correlations between Michael's animation videos and the video only videos, we must do three steps: \n",
    "1. Clean the datasets to remove participants who didn't perform as desired.\n",
    "2. Average columnwise to get the average ratings of a specific animation/video in a vector form.\n",
    "3. Calculate the correlation between the video_only condition and {mouth_only, eyes_only, and full_face} animation conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:955: UserWarning: Illegal line #1\n",
      "\t\"backend=TkAgg\"\n",
      "\tin file \"/Users/MichaelSmith/.matplotlib/matplotlibrc\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from cleanavgcorr import ParticipantResults\n",
    "import scipy.stats as st\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSV Files\n",
    "\n",
    "We read in CSV's to four lists: face, eyes, mouth, and vid_only. Each list contains twelve tuples, corresponding to the twelve videos that we tested participants on. Each tuple is of format (video_id, class ParticipantResults). \n",
    "\n",
    "*For anim_directory*: give the path to the 'val_ratings_result' folder in the 'animation_results' folder.\n",
    "\n",
    "*For vid_only_dir*: give the path to the 'videoOnly results' \n",
    "\n",
    "*For worker_info*: give the path to the worker_info.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_directory = os.fsencode('/Users/MichaelSmith/Desktop/new_animation_result/ratings')\n",
    "vid_only_dir = os.fsencode('/Users/MichaelSmith/Desktop/VideoOnly')\n",
    "worker_info = pd.read_csv('/Users/MichaelSmith/Desktop/new_animation_result/workers/worker_info_new.csv', sep=',')\n",
    "\n",
    "face = {}\n",
    "mouth = {}\n",
    "eyes = {}\n",
    "vid_only = {}\n",
    "\n",
    "# FACE, EYES, MOUTH ANIMATION CONDITIONS\n",
    "for file in os.listdir(anim_directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        vid_id = filename[:10]\n",
    "        df = pd.read_csv(os.path.join(os.fsdecode(anim_directory), filename))\n",
    "        if 'face' in filename:\n",
    "            pr = ParticipantResults(vid_id + '_anim_face', df, worker_info)\n",
    "            face[vid_id] = pr\n",
    "        elif 'eyes' in filename:\n",
    "            pr = ParticipantResults(vid_id + '_anim_eyes', df, worker_info)\n",
    "            eyes[vid_id] = pr\n",
    "        else:\n",
    "            pr = ParticipantResults(vid_id + '_anim_mouth', df, worker_info)\n",
    "            mouth[vid_id] = pr\n",
    "\n",
    "# VIDEO ONLY CONDITION\n",
    "for file in os.listdir(vid_only_dir):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.csv'):\n",
    "        vid_id = filename[:10]\n",
    "        df = pd.read_csv(os.path.join(os.fsdecode(vid_only_dir), filename))\n",
    "        pr = ParticipantResults(vid_id, df, worker_info)\n",
    "        vid_only[vid_id] = pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cleanavgcorr.ParticipantResults at 0x10473a278>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face['ID118_vid3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Averaging\n",
    "First, we need to clean the CSV files before we can average the participants' ratings. The type of cleaning depends on\n",
    "the CSV. \n",
    "\n",
    "##### Removal Conditions:\n",
    "For the animation CSVs (only), we have information on the attention of the participants (time spent on the tab = i.e. 1 - time on other tab(s)); if attention falls below 75% **(subject to change)**, we remove that participant's trial results. For both the video-only and animation conditions, we remove a participant's trial if they do not move the slider bar at least three times **(subject to change)**. These variables can be changed in the ParticipantResults class.\n",
    "\n",
    "This leaves us with datasets of size (num_participants x time).\n",
    "##### Averaging:\n",
    "We average each dataset columnwise, across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num people thrown out for video ID173_vid6_anim_face: 4 out of 37 participants\n",
      "Num people thrown out for video ID173_vid6_anim_eyes: 2 out of 26 participants\n",
      "Num people thrown out for video ID173_vid6_anim_mouth: 3 out of 27 participants\n",
      "Num people thrown out for video ID173_vid6: 9 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID120_vid1_anim_face: 6 out of 35 participants\n",
      "Num people thrown out for video ID120_vid1_anim_eyes: 2 out of 23 participants\n",
      "Num people thrown out for video ID120_vid1_anim_mouth: 6 out of 32 participants\n",
      "Num people thrown out for video ID120_vid1: 5 out of 64 participants\n",
      "\n",
      "Num people thrown out for video ID174_vid2_anim_face: 5 out of 34 participants\n",
      "Num people thrown out for video ID174_vid2_anim_eyes: 4 out of 24 participants\n",
      "Num people thrown out for video ID174_vid2_anim_mouth: 4 out of 32 participants\n",
      "Num people thrown out for video ID174_vid2: 10 out of 69 participants\n",
      "\n",
      "Num people thrown out for video ID151_vid2_anim_face: 9 out of 30 participants\n",
      "Num people thrown out for video ID151_vid2_anim_eyes: 8 out of 25 participants\n",
      "Num people thrown out for video ID151_vid2_anim_mouth: 8 out of 35 participants\n",
      "Num people thrown out for video ID151_vid2: 11 out of 58 participants\n",
      "\n",
      "Num people thrown out for video ID135_vid3_anim_face: 1 out of 28 participants\n",
      "Num people thrown out for video ID135_vid3_anim_eyes: 4 out of 32 participants\n",
      "Num people thrown out for video ID135_vid3_anim_mouth: 4 out of 30 participants\n",
      "Num people thrown out for video ID135_vid3: 6 out of 56 participants\n",
      "\n",
      "Num people thrown out for video ID161_vid3_anim_face: 4 out of 28 participants\n",
      "Num people thrown out for video ID161_vid3_anim_eyes: 6 out of 30 participants\n",
      "Num people thrown out for video ID161_vid3_anim_mouth: 8 out of 32 participants\n",
      "Num people thrown out for video ID161_vid3: 13 out of 54 participants\n",
      "\n",
      "Num people thrown out for video ID169_vid4_anim_face: 7 out of 29 participants\n",
      "Num people thrown out for video ID169_vid4_anim_eyes: 7 out of 25 participants\n",
      "Num people thrown out for video ID169_vid4_anim_mouth: 12 out of 36 participants\n",
      "Num people thrown out for video ID169_vid4: 7 out of 50 participants\n",
      "\n",
      "Num people thrown out for video ID181_vid2_anim_face: 2 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2_anim_eyes: 4 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2_anim_mouth: 2 out of 30 participants\n",
      "Num people thrown out for video ID181_vid2: 6 out of 67 participants\n",
      "\n",
      "Num people thrown out for video ID147_vid5_anim_face: 4 out of 31 participants\n",
      "Num people thrown out for video ID147_vid5_anim_eyes: 2 out of 29 participants\n",
      "Num people thrown out for video ID147_vid5_anim_mouth: 4 out of 30 participants\n",
      "Num people thrown out for video ID147_vid5: 6 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID167_vid2_anim_face: 4 out of 30 participants\n",
      "Num people thrown out for video ID167_vid2_anim_eyes: 7 out of 34 participants\n",
      "Num people thrown out for video ID167_vid2_anim_mouth: 8 out of 26 participants\n",
      "Num people thrown out for video ID167_vid2: 6 out of 63 participants\n",
      "\n",
      "Num people thrown out for video ID119_vid4_anim_face: 9 out of 27 participants\n",
      "Num people thrown out for video ID119_vid4_anim_eyes: 9 out of 32 participants\n",
      "Num people thrown out for video ID119_vid4_anim_mouth: 9 out of 31 participants\n",
      "Num people thrown out for video ID119_vid4: 8 out of 50 participants\n",
      "\n",
      "Num people thrown out for video ID120_vid4_anim_face: 0 out of 28 participants\n",
      "Num people thrown out for video ID120_vid4_anim_eyes: 5 out of 41 participants\n",
      "Num people thrown out for video ID120_vid4_anim_mouth: 3 out of 21 participants\n",
      "Num people thrown out for video ID120_vid4: 6 out of 55 participants\n",
      "\n",
      "Num people thrown out for video ID181_vid4_anim_face: 7 out of 34 participants\n",
      "Num people thrown out for video ID181_vid4_anim_eyes: 11 out of 33 participants\n",
      "Num people thrown out for video ID181_vid4_anim_mouth: 10 out of 23 participants\n",
      "Num people thrown out for video ID181_vid4: 6 out of 55 participants\n",
      "\n",
      "Num people thrown out for video ID129_vid5_anim_face: 3 out of 24 participants\n",
      "Num people thrown out for video ID129_vid5_anim_eyes: 4 out of 32 participants\n",
      "Num people thrown out for video ID129_vid5_anim_mouth: 2 out of 34 participants\n",
      "Num people thrown out for video ID129_vid5: 9 out of 65 participants\n",
      "\n",
      "Num people thrown out for video ID137_vid6_anim_face: 4 out of 23 participants\n",
      "Num people thrown out for video ID137_vid6_anim_eyes: 5 out of 28 participants\n",
      "Num people thrown out for video ID137_vid6_anim_mouth: 8 out of 39 participants\n",
      "Num people thrown out for video ID137_vid6: 9 out of 60 participants\n",
      "\n",
      "Num people thrown out for video ID118_vid3_anim_face: 5 out of 29 participants\n",
      "Num people thrown out for video ID118_vid3_anim_eyes: 6 out of 31 participants\n",
      "Num people thrown out for video ID118_vid3_anim_mouth: 8 out of 30 participants\n",
      "Num people thrown out for video ID118_vid3: 9 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID128_vid2_anim_face: 9 out of 33 participants\n",
      "Num people thrown out for video ID128_vid2_anim_eyes: 5 out of 29 participants\n",
      "Num people thrown out for video ID128_vid2_anim_mouth: 4 out of 28 participants\n",
      "Num people thrown out for video ID128_vid2: 15 out of 69 participants\n",
      "\n",
      "Num people thrown out for video ID147_vid2_anim_face: 3 out of 27 participants\n",
      "Num people thrown out for video ID147_vid2_anim_eyes: 7 out of 28 participants\n",
      "Num people thrown out for video ID147_vid2_anim_mouth: 3 out of 35 participants\n",
      "Num people thrown out for video ID147_vid2: 8 out of 51 participants\n",
      "\n",
      "Num people thrown out for video ID171_vid1_anim_face: 8 out of 39 participants\n",
      "Num people thrown out for video ID171_vid1_anim_eyes: 1 out of 30 participants\n",
      "Num people thrown out for video ID171_vid1_anim_mouth: 5 out of 21 participants\n",
      "Num people thrown out for video ID171_vid1: 13 out of 54 participants\n",
      "\n",
      "Num people thrown out for video ID170_vid2_anim_face: 3 out of 29 participants\n",
      "Num people thrown out for video ID170_vid2_anim_eyes: 5 out of 31 participants\n",
      "Num people thrown out for video ID170_vid2_anim_mouth: 5 out of 30 participants\n",
      "Num people thrown out for video ID170_vid2: 14 out of 56 participants\n",
      "\n",
      "Num people thrown out for video ID153_vid3_anim_face: 8 out of 32 participants\n",
      "Num people thrown out for video ID153_vid3_anim_eyes: 6 out of 39 participants\n",
      "Num people thrown out for video ID153_vid3_anim_mouth: 4 out of 19 participants\n",
      "Num people thrown out for video ID153_vid3: 8 out of 59 participants\n",
      "\n",
      "Num people thrown out for video ID129_vid2_anim_face: 8 out of 30 participants\n",
      "Num people thrown out for video ID129_vid2_anim_eyes: 5 out of 31 participants\n",
      "Num people thrown out for video ID129_vid2_anim_mouth: 4 out of 29 participants\n",
      "Num people thrown out for video ID129_vid2: 13 out of 61 participants\n",
      "\n",
      "Num people thrown out for video ID174_vid3_anim_face: 2 out of 25 participants\n",
      "Num people thrown out for video ID174_vid3_anim_eyes: 6 out of 32 participants\n",
      "Num people thrown out for video ID174_vid3_anim_mouth: 1 out of 33 participants\n",
      "Num people thrown out for video ID174_vid3: 9 out of 60 participants\n",
      "\n",
      "Num people thrown out for video ID121_vid5_anim_face: 7 out of 28 participants\n",
      "Num people thrown out for video ID121_vid5_anim_eyes: 2 out of 25 participants\n",
      "Num people thrown out for video ID121_vid5_anim_mouth: 6 out of 37 participants\n",
      "Num people thrown out for video ID121_vid5: 16 out of 66 participants\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can call clean as many times as possible - but cleaning only works once. Same with averaging.\n",
    "for key in vid_only:\n",
    "    face[key].clean()\n",
    "    face[key].compute_average()\n",
    "    eyes[key].clean()\n",
    "    eyes[key].compute_average()\n",
    "    mouth[key].clean()\n",
    "    mouth[key].compute_average()\n",
    "    vid_only[key].clean(anim=False)\n",
    "    vid_only[key].compute_average()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlating\n",
    "\n",
    "For each of the three conditions ({eyes_only, jaw/mouth_only, full_face}), we correlate with the video_only condition for each video before averaging across all videos. We use pearson's r for correlating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For video ID173_vid6: corr's btwn video_only and face, mouth, and eyes are: 0.758982, -0.125961, 0.005120\n",
      "For video ID120_vid1: corr's btwn video_only and face, mouth, and eyes are: 0.820400, 0.231546, -0.164377\n",
      "For video ID174_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.548788, 0.342210, -0.505821\n",
      "For video ID151_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.487768, 0.904871, 0.624628\n",
      "For video ID135_vid3: corr's btwn video_only and face, mouth, and eyes are: -0.264098, 0.554585, 0.690425\n",
      "For video ID161_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.866053, 0.683447, 0.335927\n",
      "For video ID169_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.658679, -0.056467, 0.811073\n",
      "For video ID181_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.878202, 0.867823, 0.485170\n",
      "For video ID147_vid5: corr's btwn video_only and face, mouth, and eyes are: -0.193039, 0.391303, -0.073037\n",
      "For video ID167_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.263542, 0.539132, -0.496481\n",
      "For video ID119_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.528239, 0.502573, 0.559196\n",
      "For video ID120_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.937433, 0.302573, 0.263354\n",
      "For video ID181_vid4: corr's btwn video_only and face, mouth, and eyes are: 0.860411, 0.907085, -0.127113\n",
      "For video ID129_vid5: corr's btwn video_only and face, mouth, and eyes are: 0.233362, 0.081420, 0.652618\n",
      "For video ID137_vid6: corr's btwn video_only and face, mouth, and eyes are: 0.188076, 0.164637, -0.440402\n",
      "For video ID118_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.076164, -0.195537, -0.337808\n",
      "For video ID128_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.126347, 0.517690, 0.738736\n",
      "For video ID147_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.049605, 0.588132, -0.227755\n",
      "For video ID171_vid1: corr's btwn video_only and face, mouth, and eyes are: 0.792108, 0.598641, -0.325507\n",
      "For video ID170_vid2: corr's btwn video_only and face, mouth, and eyes are: 0.746535, 0.848766, -0.194188\n",
      "For video ID153_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.594459, 0.584336, 0.926725\n",
      "For video ID129_vid2: corr's btwn video_only and face, mouth, and eyes are: -0.762712, -0.243365, 0.095808\n",
      "For video ID174_vid3: corr's btwn video_only and face, mouth, and eyes are: 0.726176, 0.819316, -0.387622\n",
      "For video ID121_vid5: corr's btwn video_only and face, mouth, and eyes are: 0.214467, -0.062888, 0.390929\n",
      "24\n",
      "24\n",
      "24\n",
      "Average Face Correlation:  0.5166894549414041\n",
      "Average Mouth Correlation:  0.4891133352699599\n",
      "Average Eyes Correlation:  0.20138367130709384\n"
     ]
    }
   ],
   "source": [
    "total_face = []\n",
    "face_pear_corr_vals = []\n",
    "total_mouth = []\n",
    "mouth_pear_corr_vals = []\n",
    "total_eyes = []\n",
    "eyes_pear_corr_vals = []\n",
    "\n",
    "for key in vid_only:\n",
    "    face_corr = face[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_face.append(np.arctanh(face_corr))\n",
    "    face_pear_corr_vals.append(face_corr)\n",
    "    mouth_corr = mouth[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_mouth.append(np.arctanh(mouth_corr))\n",
    "    mouth_pear_corr_vals.append(mouth_corr)\n",
    "    eyes_corr = eyes[key].average_df.corr(vid_only[key].average_df)\n",
    "    total_eyes.append(np.arctanh(eyes_corr))\n",
    "    eyes_pear_corr_vals.append(eyes_corr)\n",
    "    print('For video %s: corr\\'s btwn video_only and face, mouth, and eyes are: %5f, %5f, %5f' % (key, face_corr, mouth_corr, eyes_corr))\n",
    "    \n",
    "print('Average Face Correlation: ', np.tanh(np.sum(total_face)/24))\n",
    "print('Average Mouth Correlation: ', np.tanh(np.sum(total_mouth)/24))\n",
    "print('Average Eyes Correlation: ', np.tanh(np.sum(total_eyes)/24))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1092c8e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10928a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'Face':face_pear_corr_vals, 'Mouth':mouth_pear_corr_vals, 'Eyes':eyes_pear_corr_vals}).boxplot(column=['Eyes', 'Face', 'Mouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
